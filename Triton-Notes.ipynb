{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e0a013",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7dfda1",
   "metadata": {},
   "source": [
    "| 比较维度   | PyTorch                                           | Triton                                                              |\n",
    "|------------|---------------------------------------------------|---------------------------------------------------------------------|\n",
    "| 设计目的   | 深度学习框架，便于构建和训练神经网络             | 高性能计算和自定义 GPU 内核的优化                                  |\n",
    "| 编程模型   | 高层抽象，易于使用                                 | 低级控制，专注于 GPU 内核开发                                      |\n",
    "| 性能优势   | 依赖于底层库优化，适合大多数任务                 | 可编写高度优化的内核，实现更高性能                                  |\n",
    "| 可扩展性   | 灵活但在低级优化方面依赖扩展工具                 | 提供更直接的 GPU 控制，支持自定义内核开发                          |\n",
    "| 易用性     | 用户友好，适合新手和专家，入门门槛较低           | 需要 GPU 编程知识，适合有经验的用户                                 |\n",
    "| 应用场景   | 适合标准深度学习任务，如图像分类和 NLP           | 适合需要高性能自定义计算和内核优化的场景                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8b4c9",
   "metadata": {},
   "source": [
    "### 1. 计算内核"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0feeb10",
   "metadata": {},
   "source": [
    "创建一个辅助函数从而：\n",
    "\n",
    "(1) 生成 `z` 张量\n",
    "\n",
    "(2) 用适当的 grid/block sizes 将上述内核加入队列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b55d728",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@triton\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# @triton.jit 装饰器：将此 Python 函数即时编译（Just-In-Time, JIT）为高性能的 GPU 可执行内核。\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_kernel\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                \u001b[38;5;66;03m# 允许编译器执行特定优化，如循环展开和指令调度。\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'triton'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "# @triton.jit 装饰器：将此 Python 函数即时编译（Just-In-Time, JIT）为高性能的 GPU 可执行内核。\n",
    "def add_kernel(\n",
    "    x_ptr,         # 输入：指向第一个输入向量（x）在全局内存中起始地址的指针。\n",
    "    y_ptr,         # 输入：指向第二个输入向量（y）在全局内存中起始地址的指针。\n",
    "    output_ptr,    # 输出：指向输出向量在全局内存中起始地址的指针。\n",
    "    n_elements,    # 输入参数：向量的元素总数，用于边界检查。\n",
    "    BLOCK_SIZE: tl.constexpr,  # 编译时常量：定义单个程序实例处理的元素数量。\n",
    "                               # 作为 `constexpr`，该值在编译阶段即被确定，\n",
    "                               # 允许编译器执行特定优化，如循环展开和指令调度。\n",
    "):\n",
    "    \"\"\"\n",
    "    此 Triton 内核用于在 GPU 上高效执行两个向量的逐元素加法。\n",
    "    其核心策略是将大规模计算任务分解为由多个并行程序实例处理的小数据块。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 程序标识与工作负载分配\n",
    "    # GPU 以大规模并行方式启动内核，形成一个程序网格。\n",
    "    # tl.program_id(axis=0) 用于获取当前程序实例在此一维网格中的唯一标识符（ID）。\n",
    "    pid = tl.program_id(axis=0)\n",
    "\n",
    "    # 基于程序ID（pid）和块大小（BLOCK_SIZE），计算当前程序实例负责处理的数据块的起始索引。\n",
    "    # 确保不同的程序实例处理向量中不相交的数据段。\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    \n",
    "    # tl.arange(0, BLOCK_SIZE) 生成一个 [0, 1, ..., BLOCK_SIZE-1] 的序列。\n",
    "    # 与 block_start 相加后，得到当前程序实例需要操作的所有元素的绝对索引集合。\n",
    "    # 此操作是向量化的，为后续的块级内存操作提供了基础。\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    # 2. 内存访问边界检查\n",
    "    # 为保证程序的健壮性，必须防止内存访问越界，尤其是在向量总长度 n_elements\n",
    "    # 不是 BLOCK_SIZE 的整数倍时，最后一个程序实例可能会访问无效内存。\n",
    "    # 此处生成一个布尔类型的掩码，用于标识 offsets 中的索引是否在有效范围内。\n",
    "    mask = offsets < n_elements\n",
    "\n",
    "    # 3. 从全局内存 DRAM 加载数据\n",
    "    # tl.load 指令执行向量化的块加载操作，将数据从慢速的 DRAM 传输到高速的 SRAM 或寄存器中。\n",
    "    # `mask` 参数确保只加载掩码为真的有效数据，从而规避硬件异常。\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    y = tl.load(y_ptr + offsets, mask=mask)\n",
    "\n",
    "    # 4. 在片上内存中执行计算\n",
    "    # 此时 x 和 y 均为驻留在高速缓存中的数据块。\n",
    "    # 元素加法在此级别上执行，延迟极低，效率极高。\n",
    "    output = x + y\n",
    "\n",
    "    # 5. 将计算结果写回全局内存 DRAM\n",
    "    # tl.store 指令将计算结果以向量化的块形式从片上内存写回到 DRAM。\n",
    "    # 应用掩码 `mask` 可防止对向量边界之外的内存地址进行非法写入。\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3da6e",
   "metadata": {},
   "source": [
    "定义一个使用 Triton 框架编写的自定义 GPU 内核函数，用于执行两个向量的逐元素加法运算，并将结果存储在输出向量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: torch.Tensor, y: torch.Tensor):\n",
    "    \"\"\"\n",
    "    此函数作为主机端的接口，负责调用 `add_kernel` Triton 内核来执行向量加法。\n",
    "    它处理了内存分配、内核启动配置和内核执行的全过程。\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): 第一个输入张量，必须位于 CUDA 设备上。\n",
    "        y (torch.Tensor): 第二个输入张量，必须位于 CUDA 设备上。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 包含 x 和 y 逐元素相加结果的输出张量。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 输出内存预分配与验证\n",
    "    # 在 CUDA 编程中，内核通常不负责内存分配。主机代码必须预先在 GPU 设备上\n",
    "    # 为输出结果分配好内存空间。`torch.empty_like(x)` 创建一个与输入张量 x\n",
    "    # 具有相同形状、数据类型和设备位置的未初始化张量。\n",
    "    output = torch.empty_like(x)\n",
    "\n",
    "    # 断言检查，确保所有涉及的张量都已存在于 CUDA 设备上。\n",
    "    # Triton 内核只能操作 GPU 内存。\n",
    "    assert x.is_cuda and y.is_cuda and output.is_cuda, \"All tensors must be on a CUDA device.\"\n",
    "    \n",
    "    # 获取张量中的元素总数，该值将作为参数传递给内核，用于确定计算边界。\n",
    "    n_elements = output.numel()\n",
    "\n",
    "    # 2. 配置内核启动网格 \n",
    "    # 启动网格定义了需要并行启动多少个内核实例。\n",
    "    # 此处使用一维网格。网格的大小通过一个 lambda 函数动态计算：\n",
    "    # `triton.cdiv(n_elements, meta['BLOCK_SIZE'])`\n",
    "    # `triton.cdiv` 是向上取整除法，它确保即使 n_elements 不能被 BLOCK_SIZE 整除，\n",
    "    # 也能启动足够数量的程序实例来覆盖所有元素。\n",
    "    # `meta` 是一个字典，包含了在内核调用时传入的元参数（meta-parameters）。\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
    "\n",
    "    # 3. 启动 Triton 内核\n",
    "    # ====================\n",
    "    # `add_kernel[grid]`：通过附加启动网格 `grid`，将 JIT 编译的 Triton 函数 `add_kernel`\n",
    "    # 实例化为一个可调用的 GPU 内核对象。\n",
    "    \n",
    "    # `(...)`: 调用该内核对象，并传递参数。\n",
    "    #  - 位置参数 (x, y, output, n_elements):\n",
    "    #    - PyTorch 张量 `x`, `y`, `output` 会被自动转换成指向其数据在 GPU 内存中\n",
    "    #      起始位置的指针。\n",
    "    #    - `n_elements` 作为一个常规的整型值传递。\n",
    "    #  - 关键字参数 (BLOCK_SIZE=1024):\n",
    "    #    - 像 `BLOCK_SIZE` 这样的 `constexpr` 元参数必须作为关键字参数传递。\n",
    "    #      这些值在内核编译时使用，会影响最终生成的代码。\n",
    "    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n",
    "    \n",
    "    # 4. 返回结果句柄\n",
    "    # GPU 操作本质上是异步的。函数返回的是 `output` 张量的句柄。\n",
    "    # 对该张量的任何后续操作都会自动触发 CUDA 流的同步，等待内核执行完毕。\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
